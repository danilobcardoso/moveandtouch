{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "from stgcn import Model, Feeder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 3\n",
    "num_class = 400\n",
    "edge_importance_weighting = True\n",
    "graph_args = {\n",
    "    \"layout\": \"openpose\",\n",
    "    \"strategy\": \"spatial\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stgcn_original_model = Model(in_channels, num_class, graph_args, edge_importance_weighting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stgcn_state_dict = torch.load('./models/stgcn/st_gcn.kinetics-6fa43f73.pth')\n",
    "stgcn_original_model.load_state_dict(stgcn_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewModel(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "\n",
    "        # Load layers from base model\n",
    "        self.graph = base_model.graph \n",
    "        A = torch.tensor(self.graph.A,\n",
    "                         dtype=torch.float32,\n",
    "                         requires_grad=False)\n",
    "        self.register_buffer('A', A)\n",
    "\n",
    "        \n",
    "        self.st_gcn_networks = base_model.st_gcn_networks\n",
    "        self.data_bn = base_model.data_bn\n",
    "        self.edge_importance = base_model.edge_importance\n",
    "        \n",
    "        # For activity recognition\n",
    "        self.fcn = base_model.fcn\n",
    "        \n",
    "        # For point of contact prediction\n",
    "        self.poc_conv1 = nn.Conv2d(256, 128, kernel_size=1, stride=(1, 1))\n",
    "        self.poc_conv2 = nn.Conv2d(128, 64, kernel_size=1, stride=(1, 1))\n",
    "        self.poc_conv3 = nn.Conv2d(64, 1, kernel_size=1, stride=(1, 1))\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # data normalization\n",
    "        N, C, T, V, M = x.size()\n",
    "        x = x.permute(0, 4, 3, 1, 2).contiguous()\n",
    "        x = x.view(N * M, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, M, V, C, T)\n",
    "        x = x.permute(0, 1, 3, 4, 2).contiguous()\n",
    "        x = x.view(N * M, C, T, V)\n",
    "\n",
    "        # forwad\n",
    "        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):\n",
    "            x, _ = gcn(x, self.A * importance)\n",
    "\n",
    "        # BRANCH 1 - Activity recognition \n",
    "        x1 = F.avg_pool2d(x, x.size()[2:])\n",
    "        x1 = x1.view(N, M, -1, 1, 1).mean(dim=1)\n",
    "        x1 = self.fcn(x1)\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "        \n",
    "        # BRANCH 2 - Point of contact prediction\n",
    "        #print(x.size())\n",
    "        x2 = F.relu(self.poc_conv1(x))\n",
    "        #print(x2.size())\n",
    "        x2 = F.relu(self.poc_conv2(x2))\n",
    "        #print(x2.size())\n",
    "        x2 = F.sigmoid(self.poc_conv3(x2))\n",
    "        x2 = x2.view(x2.size(0), x2.size(2), x2.size(3))\n",
    "\n",
    "        return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = NewModel(stgcn_original_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeder = Feeder( './data/stgcn/val_data.npy',\n",
    "                 './data/stgcn/val_label.pkl',\n",
    "                 random_choose=False,\n",
    "                 random_move=False,\n",
    "                 window_size=-1,\n",
    "                 debug=False,\n",
    "                 mmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.tensor(feeder[0:1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = new_model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 400])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 75, 18])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5093, 0.4967, 0.5345,  ..., 0.4983, 0.4949, 0.5071],\n",
       "         [0.5172, 0.4978, 0.5409,  ..., 0.5052, 0.4932, 0.5187],\n",
       "         [0.5188, 0.5053, 0.5439,  ..., 0.4998, 0.4967, 0.5186],\n",
       "         ...,\n",
       "         [0.4831, 0.4933, 0.4964,  ..., 0.4800, 0.4840, 0.4853],\n",
       "         [0.4830, 0.4916, 0.4962,  ..., 0.4794, 0.4854, 0.4875],\n",
       "         [0.4827, 0.4912, 0.4941,  ..., 0.4812, 0.4854, 0.4880]],\n",
       "\n",
       "        [[0.4899, 0.5077, 0.5214,  ..., 0.5089, 0.4986, 0.4900],\n",
       "         [0.4844, 0.5121, 0.5150,  ..., 0.5019, 0.5069, 0.4847],\n",
       "         [0.4847, 0.5139, 0.5199,  ..., 0.5021, 0.5087, 0.4871],\n",
       "         ...,\n",
       "         [0.4831, 0.4933, 0.4964,  ..., 0.4800, 0.4840, 0.4853],\n",
       "         [0.4830, 0.4916, 0.4962,  ..., 0.4794, 0.4854, 0.4875],\n",
       "         [0.4827, 0.4912, 0.4941,  ..., 0.4812, 0.4854, 0.4880]]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 300, 18, 2])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample_from_file(path, length=300):\n",
    "    file_data = np.load(path)\n",
    "    data = file_data['arr_0']\n",
    "    data = np.transpose(data, (2, 0, 1))\n",
    "    frames = data.shape[1]\n",
    "    interval = frames/length\n",
    "    idx = np.floor(np.arange(length)*interval).astype(int)\n",
    "    touching_points = data[3,idx,:]\n",
    "    pose_sequence = data[0:3,idx,:]\n",
    "    return pose_sequence, touching_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrabFeeder(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_path, selected_classes):\n",
    "        self.data_path = data_path\n",
    "        self.selected_classes = selected_classes\n",
    "        self.length = 300\n",
    "        self.load_data()\n",
    "        \n",
    "    def load_data(self):\n",
    "        data = []\n",
    "        class_label = []\n",
    "        touching_points = []\n",
    "        for i in range(len(self.selected_classes)):\n",
    "            selected_class = self.selected_classes[i]\n",
    "            class_files = glob.glob(self.data_path + '/*'+ selected_class +'*.npz')\n",
    "            for class_file in class_files:\n",
    "                poses, tp = load_sample_from_file(class_file, length=self.length)\n",
    "                data.append(poses)\n",
    "                class_label.append(i)\n",
    "                touching_points.append(tp)\n",
    "                \n",
    "        self.class_label = class_label\n",
    "        self.tp = np.array(touching_points)\n",
    "        self.tp = self.tp.reshape(-1, int(self.length/4), 4, 18)\n",
    "        self.tp = self.tp.max(axis=2)\n",
    "        \n",
    "        self.data = np.array(data)\n",
    "        self.data = self.data.reshape((-1, 3, self.length, 18, 1))\n",
    "                \n",
    "    def __len__(self):\n",
    "        teste = len(self.class_label)\n",
    "        return teste\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        data_numpy = self.data[index]\n",
    "        label = self.class_label[index]\n",
    "        tp = self.tp[index]\n",
    "\n",
    "        return data_numpy, tp, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_classes = ['offhand', 'eat', 'drink']\n",
    "grab_feeder = GrabFeeder('../../datasets/grab_skeleton/', selected_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "\n",
    "grab_data_loader = DataLoader(grab_feeder, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "bce = nn.BCELoss()\n",
    "optimizer = optim.SGD(\n",
    "                new_model.parameters(),\n",
    "                lr=0.01,\n",
    "                momentum=0.9,\n",
    "                nesterov=True,\n",
    "                weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0162608623504639\n",
      "1.2812612056732178\n",
      "1.4361464977264404\n",
      "1.1583032608032227\n",
      "1.2963591814041138\n",
      "1.8524937629699707\n",
      "0.7327706813812256\n",
      "0.870172381401062\n",
      "0.7078036069869995\n",
      "0.5761072039604187\n",
      "1.0221362113952637\n",
      "0.7195138335227966\n",
      "0.7396740913391113\n",
      "0.7662004232406616\n",
      "1.1179569959640503\n",
      "1.1183362007141113\n",
      "1.0909100770950317\n",
      "0.5565000772476196\n",
      "0.3607386350631714\n",
      "1.2589396238327026\n",
      "1.9918822050094604\n",
      "0.3790687620639801\n",
      "0.2648668885231018\n",
      "1.3971385955810547\n",
      "0.335785448551178\n",
      "2.6895077228546143\n",
      "0.44877856969833374\n",
      "1.195904016494751\n",
      "0.36288949847221375\n",
      "2.0643327236175537\n",
      "0.5781333446502686\n",
      "1.3457486629486084\n"
     ]
    }
   ],
   "source": [
    "new_model.train()\n",
    "loss_value = []\n",
    "iter_info = {}\n",
    "\n",
    "for data, tp, label in grab_data_loader:\n",
    "    \n",
    "\n",
    "    data = data.float()\n",
    "    label = label.long()\n",
    "    tp = tp.float()\n",
    "    \n",
    "\n",
    "    \n",
    "    # forward\n",
    "    out1, out2 = new_model(data)\n",
    "    loss1 = cross_entropy(out1, label)\n",
    "    loss2 = bce(out2, tp)\n",
    "    loss = loss1 + loss2\n",
    "\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # statistics\n",
    "    iter_info['loss'] = loss.data.item()\n",
    "    iter_info['lr'] = '{:.6f}'.format(0.01)\n",
    "    loss_value.append(iter_info['loss'])\n",
    "    print(iter_info['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, tp, label = grab_feeder[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_n = torch.tensor(data[0:2]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 300, 18, 1])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256, 75, 18])\n",
      "torch.Size([2, 128, 75, 18])\n",
      "torch.Size([2, 64, 75, 18])\n"
     ]
    }
   ],
   "source": [
    "x1, x2 = new_model(sample_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 400])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 75, 18])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 300, 18)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 75, 18])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.view(x2.size(0), x2.size(2), x2.size(3)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = tp.reshape(2, int(300/4), 4, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 75, 18)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste = tp.reshape(2, int(300/4), 4, 18)\n",
    "teste.max(axis=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1.0,0.0,1.0],[0.0,1.0,0.0]])\n",
    "b = np.array([[1.0,1.0,1.0],[0.0,1.0,0.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16.6667, dtype=torch.float64)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(a)\n",
    "b = torch.tensor(b)\n",
    "loss(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
